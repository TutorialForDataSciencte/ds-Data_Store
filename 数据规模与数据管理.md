# 数据规模和数据管理

随着数据规模的增加,数据管理手段和工具都需要做出响应变化,管理10个用户的数据使用excel就可以,管理100个用户的数据可能就需要用上关系数据库了,管理10万个用户可能就得用上缓存,管理100万个用户的数据可能就得使用分库分表,拆分业务逻辑等优化手段,数据库集群这样的技术.而更多的用户可能就得使用一些大数据工具了.

之所以不同规模的数据要用不通的技术手段,根本上来说是机器的资源无法满足大规模存储/计算的需求.再往深了说是高资源配置的机器太贵了.因此可以看到几乎所有的大数据解决方案都是集群化方案--利用大量便宜的低配置机器组成集群,通过调度管理程序统一调配资源:

1. 将任务拆分重构为子任务构成的任务图放入调度器
2. 借助队列将任务分发到多台机器处理然后再聚合


数据管理当然也需要根据不同的数据规模来调整数据管理方式和使用的工具.


## 数据流转的基本思路



## 不同规模下的技术选型

